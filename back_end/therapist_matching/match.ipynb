{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, MultiLabelBinarizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file: ['user_id', 'name', 'gender', 'preferred_modality', 'preferred_gender', 'preferred_language', 'preferred_days', 'preferred_mode', 'preferred_specialties', 'preferred_therapist_id']\n"
     ]
    }
   ],
   "source": [
    "user = pd.read_csv('data/users.csv')\n",
    "print(\"Columns in the CSV file:\", user.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file: ['id', 'therapist_name', 'gender', 'modality', 'language', 'available_days', 'mode', 'experience_years', 'specialties']\n"
     ]
    }
   ],
   "source": [
    "therapist = pd.read_csv('data/therapists.csv')\n",
    "print(\"Columns in the CSV file:\", therapist.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelBinarizerWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.mlb.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.mlb.transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "users_df = pd.read_csv('data/users.csv')\n",
    "therapists_df = pd.read_csv('data/therapists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights for each feature:\n",
      "modality_match: 0.7118\n",
      "gender_match: 0.4513\n",
      "language_match: -0.0339\n",
      "mode_match: -0.1996\n",
      "days_overlap: 0.4463\n",
      "specialties_overlap: 0.6322\n",
      "experience_years: 0.1413\n",
      "Intercept: -1.1499\n",
      "Logistic regression model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors for user-therapist pairs\n",
    "def create_features(user, therapist):\n",
    "    features = []\n",
    "    \n",
    "    # Feature 1: Match on modality\n",
    "    features.append(1 if user['preferred_modality'] == therapist['modality'] else 0)\n",
    "    \n",
    "    # Feature 2: Match on gender\n",
    "    features.append(1 if user['preferred_gender'] == therapist['gender'] else 0)\n",
    "    \n",
    "    # Feature 3: Match on language\n",
    "    features.append(1 if user['preferred_language'] == therapist['language'] else 0)\n",
    "    \n",
    "    # Feature 4: Match on mode\n",
    "    features.append(1 if user['preferred_mode'] == therapist['mode'] else 0)\n",
    "    \n",
    "    # Feature 5: Overlap in days (at least one day in common)\n",
    "    user_days = set(user['preferred_days'].split(',')) if pd.notna(user['preferred_days']) else set()\n",
    "    therapist_days = set(therapist['available_days'].split(',')) if pd.notna(therapist['available_days']) else set()\n",
    "    features.append(1 if user_days.intersection(therapist_days) else 0)\n",
    "    \n",
    "    # Feature 6: Overlap in specialties (count of overlapping specialties)\n",
    "    user_specialties = set(user['preferred_specialties'].split(',')) if pd.notna(user['preferred_specialties']) else set()\n",
    "    therapist_specialties = set(therapist['specialties'].split(',')) if pd.notna(therapist['specialties']) else set()\n",
    "    features.append(len(user_specialties.intersection(therapist_specialties)))\n",
    "    \n",
    "    # Feature 7: Therapist experience years\n",
    "    features.append(therapist['experience_years'] if pd.notna(therapist['experience_years']) else 0)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Create training data using preferred_therapist_id as the label\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for _, user in users_df.iterrows():\n",
    "    preferred_therapist_id = user['preferred_therapist_id']\n",
    "    if pd.isna(preferred_therapist_id):\n",
    "        continue  # Skip users with no preferred therapist\n",
    "    \n",
    "    for _, therapist in therapists_df.iterrows():\n",
    "        features = create_features(user, therapist)\n",
    "        X_train.append(features)\n",
    "        # Label: 1 if this therapist is the preferred one, 0 otherwise\n",
    "        y_train.append(1 if therapist['id'] == preferred_therapist_id else 0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train logistic regression\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')  # Handle imbalanced data\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the learned weights\n",
    "feature_names = [\n",
    "    \"modality_match\", \"gender_match\", \"language_match\", \"mode_match\",\n",
    "    \"days_overlap\", \"specialties_overlap\", \"experience_years\"\n",
    "]\n",
    "weights = logreg.coef_[0]\n",
    "print(\"Learned weights for each feature:\")\n",
    "for name, weight in zip(feature_names, weights):\n",
    "    print(f\"{name}: {weight:.4f}\")\n",
    "print(f\"Intercept: {logreg.intercept_[0]:.4f}\")\n",
    "\n",
    "# Save the scaler and model\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(logreg, 'logreg_model.pkl')\n",
    "\n",
    "print(\"Logistic regression model trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: -4\n",
      "Episode 2, Total Reward: -2\n",
      "Episode 3, Total Reward: 2\n",
      "Episode 4, Total Reward: -6\n",
      "Episode 5, Total Reward: -2\n",
      "Episode 6, Total Reward: 4\n",
      "Episode 7, Total Reward: 4\n",
      "Episode 8, Total Reward: 0\n",
      "Episode 9, Total Reward: 0\n",
      "Episode 10, Total Reward: 2\n",
      "Episode 11, Total Reward: -2\n",
      "Episode 12, Total Reward: -4\n",
      "Episode 13, Total Reward: -8\n",
      "Episode 14, Total Reward: 4\n",
      "Episode 15, Total Reward: 2\n",
      "Episode 16, Total Reward: 2\n",
      "Episode 17, Total Reward: 0\n",
      "Episode 18, Total Reward: -4\n",
      "Episode 19, Total Reward: -4\n",
      "Episode 20, Total Reward: 4\n",
      "Episode 21, Total Reward: 0\n",
      "Episode 22, Total Reward: 0\n",
      "Episode 23, Total Reward: 2\n",
      "Episode 24, Total Reward: -2\n",
      "Episode 25, Total Reward: 0\n",
      "Episode 26, Total Reward: 0\n",
      "Episode 27, Total Reward: 0\n",
      "Episode 28, Total Reward: 2\n",
      "Episode 29, Total Reward: 2\n",
      "Episode 30, Total Reward: 0\n",
      "Episode 31, Total Reward: 2\n",
      "Episode 32, Total Reward: -4\n",
      "Episode 33, Total Reward: 6\n",
      "Episode 34, Total Reward: 4\n",
      "Episode 35, Total Reward: 2\n",
      "Episode 36, Total Reward: 2\n",
      "Episode 37, Total Reward: 4\n",
      "Episode 38, Total Reward: -2\n",
      "Episode 39, Total Reward: 0\n",
      "Episode 40, Total Reward: 0\n",
      "Episode 41, Total Reward: 4\n",
      "Episode 42, Total Reward: 0\n",
      "Episode 43, Total Reward: 4\n",
      "Episode 44, Total Reward: 2\n",
      "Episode 45, Total Reward: 8\n",
      "Episode 46, Total Reward: -4\n",
      "Episode 47, Total Reward: 0\n",
      "Episode 48, Total Reward: 6\n",
      "Episode 49, Total Reward: -2\n",
      "Episode 50, Total Reward: 2\n",
      "Episode 51, Total Reward: 4\n",
      "Episode 52, Total Reward: 0\n",
      "Episode 53, Total Reward: 2\n",
      "Episode 54, Total Reward: -2\n",
      "Episode 55, Total Reward: -4\n",
      "Episode 56, Total Reward: 2\n",
      "Episode 57, Total Reward: -6\n",
      "Episode 58, Total Reward: 4\n",
      "Episode 59, Total Reward: 0\n",
      "Episode 60, Total Reward: 0\n",
      "Episode 61, Total Reward: -2\n",
      "Episode 62, Total Reward: 4\n",
      "Episode 63, Total Reward: -4\n",
      "Episode 64, Total Reward: 0\n",
      "Episode 65, Total Reward: 2\n",
      "Episode 66, Total Reward: 4\n",
      "Episode 67, Total Reward: 6\n",
      "Episode 68, Total Reward: 6\n",
      "Episode 69, Total Reward: 0\n",
      "Episode 70, Total Reward: -2\n",
      "Episode 71, Total Reward: 2\n",
      "Episode 72, Total Reward: 6\n",
      "Episode 73, Total Reward: 2\n",
      "Episode 74, Total Reward: 4\n",
      "Episode 75, Total Reward: 0\n",
      "Episode 76, Total Reward: 0\n",
      "Episode 77, Total Reward: 0\n",
      "Episode 78, Total Reward: 0\n",
      "Episode 79, Total Reward: -2\n",
      "Episode 80, Total Reward: 6\n",
      "Episode 81, Total Reward: -2\n",
      "Episode 82, Total Reward: -2\n",
      "Episode 83, Total Reward: -2\n",
      "Episode 84, Total Reward: 0\n",
      "Episode 85, Total Reward: 2\n",
      "Episode 86, Total Reward: 4\n",
      "Episode 87, Total Reward: 2\n",
      "Episode 88, Total Reward: -4\n",
      "Episode 89, Total Reward: 8\n",
      "Episode 90, Total Reward: -4\n",
      "Episode 91, Total Reward: 8\n",
      "Episode 92, Total Reward: -4\n",
      "Episode 93, Total Reward: 4\n",
      "Episode 94, Total Reward: 2\n",
      "Episode 95, Total Reward: -2\n",
      "Episode 96, Total Reward: 2\n",
      "Episode 97, Total Reward: 2\n",
      "Episode 98, Total Reward: -2\n",
      "Episode 99, Total Reward: -4\n",
      "Episode 100, Total Reward: -2\n",
      "Updated model saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert logistic regression to PyTorch for RL updates\n",
    "class LogisticRegressionTorch(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionTorch, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Initialize PyTorch model with weights from sklearn\n",
    "input_dim = X_train.shape[1]\n",
    "model = LogisticRegressionTorch(input_dim)\n",
    "\n",
    "# Copy weights from sklearn model\n",
    "with torch.no_grad():\n",
    "    model.linear.weight.data = torch.tensor(logreg.coef_, dtype=torch.float32)\n",
    "    model.linear.bias.data = torch.tensor(logreg.intercept_, dtype=torch.float32)\n",
    "\n",
    "# Define optimizer for RL updates\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Simulate user feedback (replace with real feedback in practice)\n",
    "def simulate_feedback(user_id, therapist_id):\n",
    "    # Placeholder: simulate feedback (+1 for good match, -1 for bad)\n",
    "    # In practice, replace with real user feedback (e.g., ratings)\n",
    "    return np.random.choice([1, -1])\n",
    "\n",
    "# Step 6: RL training loop (policy gradient) - Fixed version\n",
    "def rl_update(model, scaler, users_df, therapists_df, num_episodes=100):\n",
    "    model.train()  # Set model to training mode to ensure gradients are tracked\n",
    "    for episode in range(num_episodes):\n",
    "        total_reward = 0\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        \n",
    "        for _, user in users_df.sample(frac=0.1).iterrows():\n",
    "            scores = []\n",
    "            therapist_ids = []\n",
    "            \n",
    "            # Compute scores for all therapists\n",
    "            for _, therapist in therapists_df.iterrows():\n",
    "                features = create_features(user, therapist)\n",
    "                features_scaled = scaler.transform([features])[0]\n",
    "                features_tensor = torch.tensor(features_scaled, dtype=torch.float32, requires_grad=True)\n",
    "                prob = model(features_tensor)  # Ensure prob is part of the computation graph\n",
    "                scores.append(prob)  # Keep as tensor, don't convert to item yet\n",
    "                therapist_ids.append(therapist['id'])\n",
    "            \n",
    "            # Stack scores into a tensor\n",
    "            scores_tensor = torch.stack(scores).squeeze()  # Shape: [num_therapists]\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(scores_tensor, dim=0)  # Shape: [num_therapists]\n",
    "            \n",
    "            # Sample an action (therapist) using Categorical distribution\n",
    "            dist = torch.distributions.Categorical(probs=probs)\n",
    "            action = dist.sample()  # Sample an action index\n",
    "            log_prob = dist.log_prob(action)  # Compute log probability of the action\n",
    "            \n",
    "            # Get reward (simulated feedback)\n",
    "            therapist_id = therapist_ids[action.item()]\n",
    "            reward = simulate_feedback(user['user_id'], therapist_id)\n",
    "            \n",
    "            log_probs.append(log_prob)\n",
    "            rewards.append(reward)\n",
    "            total_reward += reward\n",
    "        \n",
    "        # Compute policy loss\n",
    "        policy_loss = []\n",
    "        for log_prob, reward in zip(log_probs, rewards):\n",
    "            # Ensure reward is a scalar float or tensor, not a list or array\n",
    "            reward_tensor = torch.tensor(float(reward), requires_grad=False)\n",
    "            policy_loss.append(-log_prob * reward_tensor)\n",
    "        \n",
    "        # Stack and compute mean loss\n",
    "        policy_loss = torch.stack(policy_loss).mean()\n",
    "        \n",
    "        # Backpropagate and update model\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Run RL updates\n",
    "rl_update(model, scaler, users_df, therapists_df)\n",
    "\n",
    "# Save the updated model\n",
    "torch.save(model.state_dict(), 'logreg_rl_model.pth')\n",
    "print(\"Updated model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: 'therapist.csv'. Please ensure 'therapists.csv' is in the correct directory.\n",
      "\n",
      "Top 5 therapists for manually provided user:\n",
      "Therapist ID: 200, Name: Dr. Betelhem Alemu, Score: 0.1045\n",
      "Therapist ID: 262, Name: Dr. Fikadu Alemu, Score: 0.1045\n",
      "Therapist ID: 195, Name: Dr. Arsema Tsegaye, Score: 0.1045\n",
      "Therapist ID: 21, Name: Dr. Bereket Ke/bede, Score: 0.1045\n",
      "Therapist ID: 96, Name: Dr. Worku Abdullahi, Score: 0.1045\n",
      "\n",
      "Suggesting top 5 therapists for user: Chala Teshome (User ID: 5)\n",
      "Therapist ID: 154, Name: Dr. Saba Zewdu, Score: 0.9815\n",
      "Therapist ID: 238, Name: Dr. Gashaw Tadesse, Score: 0.9773\n",
      "Therapist ID: 370, Name: Dr. Gashaw Desta, Score: 0.9599\n",
      "Therapist ID: 206, Name: Dr. Gebeyaw Alemu, Score: 0.9520\n",
      "Therapist ID: 143, Name: Dr. Kebede Belay, Score: 0.9484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "\n",
    "# Step 1: Define the LogisticRegressionTorch class (same as during training)\n",
    "class LogisticRegressionTorch(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionTorch, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Step 2: Load the scaler and model\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "input_dim = 7  # Match the input_dim from training (number of features)\n",
    "model = LogisticRegressionTorch(input_dim)\n",
    "model.load_state_dict(torch.load('logreg_rl_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Load therapist data\n",
    "try:\n",
    "    therapists_df = pd.read_csv('therapist.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please ensure 'therapists.csv' is in the correct directory.\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 4: Define the create_features function (same as during training)\n",
    "def create_features(user, therapist):\n",
    "    features = []\n",
    "    features.append(1 if user['preferred_modality'] == therapist['modality'] else 0)\n",
    "    features.append(1 if user['preferred_gender'] == therapist['gender'] else 0)\n",
    "    features.append(1 if user['preferred_language'] == therapist['language'] else 0)\n",
    "    features.append(1 if user['preferred_mode'] == therapist['mode'] else 0)\n",
    "    user_days = set(user['preferred_days'].split(',')) if pd.notna(user['preferred_days']) else set()\n",
    "    therapist_days = set(therapist['available_days'].split(',')) if pd.notna(therapist['available_days']) else set()\n",
    "    features.append(1 if user_days.intersection(therapist_days) else 0)\n",
    "    user_specialties = set(user['preferred_specialties'].split(',')) if pd.notna(user['preferred_specialties']) else set()\n",
    "    therapist_specialties = set(therapist['specialties'].split(',')) if pd.notna(therapist['specialties']) else set()\n",
    "    features.append(len(user_specialties.intersection(therapist_specialties)))\n",
    "    features.append(therapist['experience_years'] if pd.notna(therapist['experience_years']) else 0)\n",
    "    return np.array(features)\n",
    "\n",
    "# Step 5: Define a function to suggest top 5 therapists for a user\n",
    "def suggest_top_5_therapists(user_data, therapists_df, scaler, model):\n",
    "    scores = []\n",
    "    therapist_ids = []\n",
    "    \n",
    "    # Compute scores for all therapists\n",
    "    for _, therapist in therapists_df.iterrows():\n",
    "        features = create_features(user_data, therapist)\n",
    "        features_scaled = scaler.transform([features])[0]\n",
    "        features_tensor = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            prob = model(features_tensor).item()\n",
    "        scores.append(prob)\n",
    "        therapist_ids.append(therapist['id'])\n",
    "    \n",
    "    # Get top 5 therapists\n",
    "    top_indices = np.argsort(scores)[-5:][::-1]  # Sort in descending order and take top 5\n",
    "    top_therapists = [\n",
    "        {\n",
    "            \"therapist_id\": therapist_ids[i],\n",
    "            \"therapist_name\": therapists_df.loc[therapists_df['id'] == therapist_ids[i], 'therapist_name'].iloc[0],\n",
    "            \"score\": scores[i]\n",
    "        }\n",
    "        for i in top_indices\n",
    "    ]\n",
    "    \n",
    "    return top_therapists\n",
    "\n",
    "# Step 6: Example usage\n",
    "# Option 1: Provide user data manually as a dictionary\n",
    "user_data_manual = pd.Series({\n",
    "    \"preferred_modality\": \"CBT\",\n",
    "    \"preferred_gender\": \"female\",\n",
    "    \"preferred_language\": \"English\",\n",
    "    \"preferred_days\": \"Monday,Wednesday\",\n",
    "    \"preferred_mode\": \"in-person\",\n",
    "    \"preferred_specialties\": \"anxiety,depression\",\n",
    "    \"age\": 30  # Not used in features but included for completeness\n",
    "})\n",
    "\n",
    "top_5 = suggest_top_5_therapists(user_data_manual, therapists_df, scaler, model)\n",
    "print(\"\\nTop 5 therapists for manually provided user:\")\n",
    "for therapist in top_5:\n",
    "    print(f\"Therapist ID: {therapist['therapist_id']}, Name: {therapist['therapist_name']}, Score: {therapist['score']:.4f}\")\n",
    "\n",
    "# Option 2: Pick a user from users.csv for demonstration\n",
    "try:\n",
    "    users_df = pd.read_csv('data/users.csv')\n",
    "    if not users_df.empty:\n",
    "        # Pick the first user for demonstration (you can change the index or user_id)\n",
    "        sample_user = users_df.iloc[0]\n",
    "        print(f\"\\nSuggesting top 5 therapists for user: {sample_user['name']} (User ID: {sample_user['user_id']})\")\n",
    "        top_5 = suggest_top_5_therapists(sample_user, therapists_df, scaler, model)\n",
    "        for therapist in top_5:\n",
    "            print(f\"Therapist ID: {therapist['therapist_id']}, Name: {therapist['therapist_name']}, Score: {therapist['score']:.4f}\")\n",
    "    else:\n",
    "        print(\"No users found in user.csv.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Could not load user.csv for demonstration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
